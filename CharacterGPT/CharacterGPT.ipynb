{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7524ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.76.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bert-score in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from bert-score) (2.6.0+cpu)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from bert-score) (4.51.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from bert-score) (2.2.4)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.12/site-packages (from bert-score) (3.10.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2025.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->bert-score) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->bert-score) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->bert-score) (3.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->bert-score) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->bert-score) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->bert-score) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (2.6.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rouge-score in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rouge-score) (2.2.2)\n",
      "Requirement already satisfied: nltk in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from rouge-score) (2.2.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/codespace/.local/lib/python3.12/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk->rouge-score) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: evaluate in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: rouge_score in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from evaluate) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from evaluate) (2.2.4)\n",
      "Requirement already satisfied: dill in /usr/local/python/3.12.1/lib/python3.12/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/codespace/.local/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/python/3.12.1/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/python/3.12.1/lib/python3.12/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/codespace/.local/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/codespace/.local/lib/python3.12/site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.11.18)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install openai python library\n",
    "%pip install openai\n",
    "%pip install bert-score\n",
    "%pip install -U sentence-transformers\n",
    "%pip install rouge-score\n",
    "%pip install evaluate rouge_score nltk absl-py\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd50bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered conversations: 3230\n",
      "Memorization test cases available: 2348\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"friends_transcripts.csv\")\n",
    "\n",
    "conversations = []\n",
    "current_convo = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if row['tokens'] == \"[]\":\n",
    "        if current_convo:\n",
    "            conversations.append(current_convo)\n",
    "            current_convo = []\n",
    "    else:\n",
    "        current_convo.append(row)\n",
    "\n",
    "# Append last convo if not terminated by '{}'\n",
    "if current_convo:\n",
    "    conversations.append(current_convo)\n",
    "\n",
    "core_characters = {\"Chandler Bing\", \"Monica Geller\", \"Joey Tribbiani\", \"Ross Geller\", \"Rachel Green\", \"Phoebe Buffay\"}\n",
    "\n",
    "filtered_conversations = []\n",
    "for convo in conversations:\n",
    "    if all(turn['speaker'] in core_characters for turn in convo):\n",
    "        filtered_conversations.append(convo)\n",
    "\n",
    "\n",
    "\n",
    "# # Sample 10 tests\n",
    "# memorization_tests = random.sample(memorization_tests, 10)\n",
    "print(f\"Length of filtered conversations: {len(filtered_conversations)}\")\n",
    "\n",
    "formatted_tests = []\n",
    "\n",
    "for convo in filtered_conversations:\n",
    "    if len(convo) >= 3:\n",
    "        context_turns = convo[:2]\n",
    "        target_turn = convo[2]\n",
    "\n",
    "        context = \"\\n\".join([f\"{turn['speaker']}: {turn['transcript']}\" for turn in context_turns])\n",
    "\n",
    "        formatted_tests.append({\n",
    "            \"speaker\": target_turn[\"speaker\"],\n",
    "            \"context\": context,\n",
    "            \"target_speaker\": target_turn[\"speaker\"],\n",
    "            \"actual_response\": target_turn[\"transcript\"]\n",
    "        })\n",
    "print(f\"Memorization test cases available: {len(formatted_tests)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edc5b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "with open('token.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"export\") and '=' in line:\n",
    "            key_value = line.replace(\"export \", \"\", 1)\n",
    "            key, value = key_value.split('=', 1)\n",
    "            os.environ[key] = value\n",
    "# Read authentication keys from environmental variables\n",
    "\n",
    "_open_ai_tkn = os.environ.get('OPENAI_KEY')\n",
    "_project_tkn = os.environ.get('OPENAI_PROJECT')\n",
    "_organisation_tkn = os.environ.get('OPENAI_ORG')\n",
    "print(_open_ai_tkn)\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd668ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create client endpoint for accessing remote LLM\n",
    "client = OpenAI(\n",
    "  organization=_organisation_tkn,\n",
    "  project=_project_tkn,\n",
    "  api_key=_open_ai_tkn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3cb412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Case 1 ---\n",
      "ðŸŽ­ Context:\n",
      "Monica Geller: There's nothing to tell! He's just some guy I work with!\n",
      "Joey Tribbiani: C'mon, you're going out with the guy! There's gotta be something wrong with him!\n",
      "\n",
      "âœ… Actual (Chandler Bing):\n",
      "All right Joey, be nice. So does he have a hump? A hump and a hairpiece?\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "â€œYeah, like he probably thinks â€˜a moment of silenceâ€™ is when you pause for applause at a bad magic show. I mean, he canâ€™t just be a normal guy. Thatâ€™s like a unicorn that doesnâ€™t sparkle!â€\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.2515\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Case 2 ---\n",
      "ðŸŽ­ Context:\n",
      "Phoebe Buffay: Just, 'cause, I don't want her to go through what I went through with Carl- oh!\n",
      "Monica Geller: Okay, everybody relax. This is not even a date. It's just two people going out to dinner and- not having sex.\n",
      "\n",
      "âœ… Actual (Chandler Bing):\n",
      "Sounds like a date to me.\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "Could we please just call it what it is? It's not really a date until you have that awkward silence and the check comes, right? You know, at that point you're either planning the rest of your life together or rehearsing how to fake a sudden illness to escape!\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.5923\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Case 3 ---\n",
      "ðŸŽ­ Context:\n",
      "Ross Geller: Hi.\n",
      "Joey Tribbiani: This guy says hello, I wanna kill myself.\n",
      "\n",
      "âœ… Actual (Monica Geller):\n",
      "Are you okay, sweetie?\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "Oh my God, Joey! Seriously? You canâ€™t just say things like that. How about we focus on something more positive? Like, um... pizza? Or maybe I could help you find a new role to audition for? You know, something that actually makes you happy!\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.2314\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Case 4 ---\n",
      "ðŸŽ­ Context:\n",
      "Monica Geller: So you wanna tell us now, or are we waiting for four wet bridesmaids?\n",
      "Rachel Green: Oh God... well, it started about a half hour before the wedding. I was in the room where we were keeping all the presents, and I was looking at this gravy boat. This really gorgeous Lamauge gravy boat. When all of a sudden- Sweet 'n' Lo?- I realized that I was more turned on by this gravy boat than by Barry! And then I got really freaked out, and that's when it hit me: how much Barry looks like Mr. Potato Head. Y'know, I mean, I always knew looked familiar, but... Anyway, I just had to get out of there, and I started wondering 'Why am I doing this, and who am I doing this for?'. So anyway I just didn't know where to go, and I know that you and I have kinda drifted apart, but you're the only person I knew who lived here in the city.\n",
      "\n",
      "âœ… Actual (Monica Geller):\n",
      "Who wasn't invited to the wedding.\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "Oh my God, Rach! A gravy boat? Seriously? I mean, I can understand being freaked out, but Barry looking like Mr. Potato Head? That's a whole other level! You know, we really need to have a talk about your dating choices. But hey, I'm glad you came here. You're always welcome in my apartment, even if it means we have to talk about your suddenly newfound love for dishware! So, what are you thinking? We need to get you a better perspective on this before you start shopping for wedding gifts!\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.3126\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Case 5 ---\n",
      "ðŸŽ­ Context:\n",
      "Phoebe Buffay: If I let go of my hair, my head will fall off.\n",
      "Chandler Bing: Ooh, she should not be wearing those pants.\n",
      "\n",
      "âœ… Actual (Joey Tribbiani):\n",
      "I say push her down the stairs.\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "Hey, come on! Donâ€™t be mean, Chandler. Everyone has their own style. Besides, Iâ€™m sure Phoebeâ€™s hair is strong enough to hold her head up! Right, Pheebs?\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.1601\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Case 6 ---\n",
      "ðŸŽ­ Context:\n",
      "Rachel Green: C'mon Daddy, listen to me! It's like, it's like, all of my life, everyone has always told me, 'You're a shoe! You're a shoe, you're a shoe, you're a shoe!'. And today I just stopped and I said, 'What if I don't wanna be a shoe? What if I wanna be a- a purse, y'know? Or a- or a hat! No, I'm not saying I want you to buy me a hat, I'm saying I am a ha- It's a metaphor, Daddy!\n",
      "Ross Geller: You can see where he'd have trouble.\n",
      "\n",
      "âœ… Actual (Rachel Green):\n",
      "Look Daddy, it's my life. Well maybe I'll just stay here with Monica.\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "I know! But, like, it just gets to a point where you realize you want to be your own thing, right? Shoes are, like, so... predictable! And I just want to be something fabulous and fun, like a purse that you can't wait to show off! Plus, I mean, purses get to hold all the good stuff! You get it, donâ€™t you? Like, being a shoe is just... boring.\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.0798\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Case 7 ---\n",
      "ðŸŽ­ Context:\n",
      "Monica Geller: Just breathe, breathe.. that's it. Just try to think of nice calm things...\n",
      "Phoebe Buffay: Raindrops on roses and rabbits and kittens, bluebells and sleighbells and- something with mittens... La la la la...something and noodles with string. These are a few...\n",
      "\n",
      "âœ… Actual (Rachel Green):\n",
      "I'm all better now.\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "Oh my God, are we really doing this right now? I mean, I love how you two are all about the calming things, but can we just talk about how stressful this is? I donâ€™t know if I can breathe and sing about noodles at the same time! Seriously, Monica, what if we just go get some coffee instead? You know, caffeine can calm the soul... or something like that.\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.1529\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Case 8 ---\n",
      "ðŸŽ­ Context:\n",
      "Joey Tribbiani: I'm thinking we've got a bookcase here.\n",
      "Chandler Bing: It's a beautiful thing.\n",
      "\n",
      "âœ… Actual (Joey Tribbiani):\n",
      "What's this?\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "Yeah, you know what they say, â€œA bookcase is like a window to the soul!â€ Or is that a mirror? I always get those two mixed up. But, hey, can we fit a pizza in there? Because that's really all I need!\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.1217\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Case 9 ---\n",
      "ðŸŽ­ Context:\n",
      "Rachel Green: Guess what?\n",
      "Ross Geller: You got a job?\n",
      "\n",
      "âœ… Actual (Rachel Green):\n",
      "Are you kidding? I'm trained for nothing! I was laughed out of twelve interviews today.\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "No, but I did find the cutest pair of shoes ever! Seriously, theyâ€™re like, *so* perfect. I just had to share! Whatâ€™s new with you?\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.0985\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Case 10 ---\n",
      "ðŸŽ­ Context:\n",
      "Monica Geller: Well, that's it You gonna crash on the couch?\n",
      "Ross Geller: No. No, I gotta go home sometime.\n",
      "\n",
      "âœ… Actual (Monica Geller):\n",
      "You be okay?\n",
      "\n",
      "ðŸ¤– GPT Reply:\n",
      "Come on, Ross! Where are you gonna go? Your place is just full of dinosaurs and bad decisions! Just stay here for a little while longer. We can order pizza and have a â€œWe survived the dayâ€ party!\n",
      "\n",
      "ðŸ“ Cosine Similarity: 0.1894\n",
      "--------------------------------------------------\n",
      "\n",
      "Average Cosine Similarity: 0.2190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "memorization_results = []\n",
    "\n",
    "for test in tqdm(formatted_tests[:10]):\n",
    "    system_prompt = f\"You are {test['speaker']} from Friends. Respond naturally as you would in the show.\"\n",
    "    user_message = test[\"context\"] + f\"\\n{test['target_speaker']}:\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_tokens=150\n",
    "        )\n",
    "\n",
    "        gpt_reply = response.choices[0].message.content\n",
    "\n",
    "        # Evaluate similarity\n",
    "        emb1 = model.encode(test[\"actual_response\"], convert_to_tensor=True)\n",
    "        emb2 = model.encode(gpt_reply, convert_to_tensor=True)\n",
    "        cosine_sim = util.cos_sim(emb1, emb2).item()\n",
    "\n",
    "        memorization_results.append({\n",
    "            \"context\": test[\"context\"],\n",
    "            \"target_speaker\": test[\"target_speaker\"],\n",
    "            \"actual\": test[\"actual_response\"],\n",
    "            \"gpt_reply\": gpt_reply,\n",
    "            \"cosine_similarity\": cosine_sim\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating for {test['target_speaker']}: {e}\")\n",
    "\n",
    "df_results = pd.DataFrame(memorization_results)\n",
    "# print(df_results)\n",
    "for i, row in df_results.head(10).iterrows():\n",
    "    print(f\"\\n--- Test Case {i + 1} ---\")\n",
    "    print(f\"ðŸŽ­ Context:\\n{row['context']}\")\n",
    "    print(f\"\\nâœ… Actual ({row['target_speaker']}):\\n{row['actual']}\")\n",
    "    print(f\"\\nðŸ¤– GPT Reply:\\n{row['gpt_reply']}\")\n",
    "    print(f\"\\nðŸ“ Cosine Similarity: {round(row['cosine_similarity'], 4)}\")\n",
    "    print(\"-\" * 50)\n",
    "# Compute and print average cosine similarity\n",
    "avg_cosine = df_results['cosine_similarity'].mean()\n",
    "print(f\"\\nAverage Cosine Similarity: {avg_cosine:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44fd59ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 10%|â–ˆ         | 1/10 [00:08<01:15,  8.37s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 20%|â–ˆâ–ˆ        | 2/10 [00:09<00:34,  4.29s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:12<00:23,  3.37s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:16<00:23,  3.85s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:18<00:16,  3.27s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:21<00:12,  3.13s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:26<00:10,  3.56s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:28<00:06,  3.11s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:29<00:02,  2.63s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target_speaker  BERTScore_Precision  BERTScore_Recall  BERTScore_F1\n",
      "0   Chandler Bing               0.8351            0.8491        0.8421\n",
      "1   Chandler Bing               0.8249            0.8662        0.8450\n",
      "2   Monica Geller               0.8139            0.8674        0.8398\n",
      "3   Monica Geller               0.7919            0.8651        0.8269\n",
      "4  Joey Tribbiani               0.7990            0.8879        0.8411\n",
      "5    Rachel Green               0.8114            0.8588        0.8344\n",
      "6    Rachel Green               0.7851            0.8508        0.8167\n",
      "7  Joey Tribbiani               0.7879            0.8344        0.8105\n",
      "8    Rachel Green               0.8365            0.8543        0.8453\n",
      "9   Monica Geller               0.7933            0.8123        0.8027\n",
      "\n",
      "Average BERTScore:\n",
      "BERTScore_Precision    0.80790\n",
      "BERTScore_Recall       0.85463\n",
      "BERTScore_F1           0.83045\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client (already done earlier in your notebook)\n",
    "# client = OpenAI(organization=..., project=..., api_key=...)\n",
    "\n",
    "bert_results = []\n",
    "\n",
    "for test in tqdm(formatted_tests[:10]):  # Adjust number as needed\n",
    "    system_prompt = f\"You are {test['speaker']} from Friends. Respond naturally as you would in the show.\"\n",
    "    user_message = test[\"context\"] + f\"\\n{test['target_speaker']}:\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_tokens=150\n",
    "        )\n",
    "\n",
    "        gpt_reply = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Compute BERTScore\n",
    "        P, R, F1 = score([gpt_reply], [test[\"actual_response\"]], lang=\"en\", verbose=False)\n",
    "        \n",
    "        bert_results.append({\n",
    "            \"context\": test[\"context\"],\n",
    "            \"target_speaker\": test[\"target_speaker\"],\n",
    "            \"actual_response\": test[\"actual_response\"],\n",
    "            \"gpt_reply\": gpt_reply,\n",
    "            \"BERTScore_Precision\": round(P[0].item(), 4),\n",
    "            \"BERTScore_Recall\": round(R[0].item(), 4),\n",
    "            \"BERTScore_F1\": round(F1[0].item(), 4)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {test['target_speaker']}: {e}\")\n",
    "\n",
    "# Display results in DataFrame\n",
    "df_bert = pd.DataFrame(bert_results)\n",
    "print(df_bert[['target_speaker', 'BERTScore_Precision', 'BERTScore_Recall', 'BERTScore_F1']])\n",
    "# Compute and print average BERT scores\n",
    "avg_bert = df_bert[['BERTScore_Precision', 'BERTScore_Recall', 'BERTScore_F1']].mean()\n",
    "print(\"\\nAverage BERTScore:\")\n",
    "print(avg_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "000b0009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target_speaker  ROUGE-1_Precision  ROUGE-1_Recall  ROUGE-1_F1\n",
      "0   Chandler Bing             0.1064          0.3125      0.1587\n",
      "1   Chandler Bing             0.0870          0.6667      0.1538\n",
      "2   Monica Geller             0.0385          0.5000      0.0714\n",
      "3   Monica Geller             0.0230          0.2857      0.0426\n",
      "4  Joey Tribbiani             0.0400          0.2857      0.0702\n",
      "5    Rachel Green             0.0533          0.2667      0.0889\n",
      "6    Rachel Green             0.0222          0.2000      0.0400\n",
      "7  Joey Tribbiani             0.0244          0.3333      0.0455\n",
      "8    Rachel Green             0.0930          0.2500      0.1356\n",
      "9   Monica Geller             0.0189          0.3333      0.0357\n",
      "\n",
      "Average ROUGE Scores:\n",
      "ROUGE-1_Precision    0.05067\n",
      "ROUGE-1_Recall       0.34339\n",
      "ROUGE-1_F1           0.08424\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize ROUGE scorer (ROUGE-1 only)\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "\n",
    "rouge_results = []\n",
    "\n",
    "for test in tqdm(formatted_tests[:10]):  # Adjust number if needed\n",
    "    system_prompt = f\"You are {test['speaker']} from Friends. Respond naturally as you would in the show.\"\n",
    "    user_message = test[\"context\"] + f\"\\n{test['target_speaker']}:\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_tokens=150\n",
    "        )\n",
    "\n",
    "        gpt_reply = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Compute ROUGE-1\n",
    "        scores = scorer.score(test[\"actual_response\"], gpt_reply)\n",
    "        rouge1 = scores[\"rouge1\"]\n",
    "\n",
    "        rouge_results.append({\n",
    "            \"context\": test[\"context\"],\n",
    "            \"target_speaker\": test[\"target_speaker\"],\n",
    "            \"actual_response\": test[\"actual_response\"],\n",
    "            \"gpt_reply\": gpt_reply,\n",
    "            \"ROUGE-1_Precision\": round(rouge1.precision, 4),\n",
    "            \"ROUGE-1_Recall\": round(rouge1.recall, 4),\n",
    "            \"ROUGE-1_F1\": round(rouge1.fmeasure, 4)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating for {test['target_speaker']}: {e}\")\n",
    "\n",
    "# Display results in a DataFrame\n",
    "df_rouge = pd.DataFrame(rouge_results)\n",
    "print(df_rouge[['target_speaker', 'ROUGE-1_Precision', 'ROUGE-1_Recall', 'ROUGE-1_F1']])\n",
    "# Compute and print average ROUGE scores\n",
    "avg_rouge = df_rouge[['ROUGE-1_Precision', 'ROUGE-1_Recall', 'ROUGE-1_F1']].mean()\n",
    "print(\"\\nAverage ROUGE Scores:\")\n",
    "print(avg_rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a773e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target_speaker    rouge1    rouge2    rougeL\n",
      "0   Chandler Bing  0.181818  0.000000  0.145455\n",
      "1   Chandler Bing  0.105263  0.036364  0.105263\n",
      "2   Monica Geller  0.040816  0.000000  0.040816\n",
      "3   Monica Geller  0.039604  0.000000  0.039604\n",
      "4  Joey Tribbiani  0.108108  0.000000  0.108108\n",
      "5    Rachel Green  0.069767  0.000000  0.069767\n",
      "6    Rachel Green  0.078947  0.000000  0.052632\n",
      "7  Joey Tribbiani  0.086957  0.000000  0.086957\n",
      "8    Rachel Green  0.186047  0.000000  0.093023\n",
      "9   Monica Geller  0.048780  0.000000  0.048780\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Store per-convo scores\n",
    "rouge_scores_per_convo = []\n",
    "\n",
    "# Limit to the first 10 entries\n",
    "for entry in memorization_results[:10]:\n",
    "    prediction = entry[\"gpt_reply\"]\n",
    "    reference = entry[\"actual\"]\n",
    "    \n",
    "    score = rouge.compute(predictions=[prediction], references=[reference])\n",
    "    \n",
    "    entry_with_rouge = entry.copy()\n",
    "    entry_with_rouge.update({\n",
    "        \"rouge1\": score[\"rouge1\"],\n",
    "        \"rouge2\": score[\"rouge2\"],\n",
    "        \"rougeL\": score[\"rougeL\"]\n",
    "    })\n",
    "    \n",
    "    rouge_scores_per_convo.append(entry_with_rouge)\n",
    "    \n",
    "df_rouge = pd.DataFrame(rouge_scores_per_convo)\n",
    "print(df_rouge[['target_speaker', 'rouge1', 'rouge2', 'rougeL']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
